#pragma once
#include "Node.h"
#include "WtaHash.h"
#include "DensifiedMinhash.h"
#include "srp.h"
#include "LSH.h"
#include "DensifiedWtaHash.h"
#include "cnpy.h"

using namespace std;

class Layer
{
private:
	NodeType _type;
	Node** _Nodes;
	int * _randNode;
	float* _normalizationConstants;
    int*_inputIDs; //needed for SOFTMAX
    int _K, _L, _RangeRow, _previousLayerNumOfNodes, _batchsize;


public:
	int _layerID, _noOfActive;
	int _noOfNodes;
	float* _weights;
	float* _adamAvgMom;
	float* _adamAvgVel;
	float* _bias;
	LSH *_hashTables;
	WtaHash *_wtaHasher;
    DensifiedMinhash *_MinHasher;
    SparseRandomProjection *_srp;
    DensifiedWtaHash *_dwtaHasher;
	int * _binids;
	Layer(int _numNodex, int previousLayerNumOfNodes, int layerID, NodeType type, int batchsize, int K, int L, int RangePow, float Sparsity, float* weights=NULL, float* bias=NULL, float *adamAvgMom=NULL, float *adamAvgVel=NULL);
	Node* getNodebyID(int nodeID);
	Node** getAllNodes();
	void addtoHashTable(float* weights, int length, float bias, int id);
	float getNomalizationConstant(int inputID);
	int queryActiveNodeandComputeActivations(int** activenodesperlayer, float** activeValuesperlayer, int* inlenght, int layerID, int inputID,  int* label, int labelsize, float Sparsity, int iter);
	void saveWeights(string file);
	void updateTable();
	void updateRandomNodes();

	~Layer();
};

